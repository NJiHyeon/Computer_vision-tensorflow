{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cddca4c-8def-4834-a17e-7ebc9ed1f0a7",
   "metadata": {},
   "source": [
    "## Building and Training a Neural Network from Scratch\n",
    "- what computer vision and deep learning are, and how neural networks work. \n",
    "- To illustrate the latter, we described how to build a simple neural network from scratch, and how to apply it to a classification task.\n",
    "- In this first notebook, we will therefore detail the related code snippets and results from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fa3a90-fa91-4c92-bb7a-3f63e37577bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      # We use numpy to make vector and matrix computations easy.\n",
    "np.random.seed(42)      # Fixing the seed for the random number generation, to get reproducable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a24e5-e45a-428f-90fc-380fe11743de",
   "metadata": {},
   "source": [
    "### 1. At the Beginning: the Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d82c88-743d-48ed-bcef-80826a9f6596",
   "metadata": {},
   "source": [
    "- 클래스는 입력 값의 벡터를 수신하여 활성화 값을 반환하기 전에 병합하고 처리할 수 있는 간단한 인공 뉴런을 나타냅니다.\n",
    "- Note: 이 클래스는 neuron.py에서도 찾을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd9d994-f41d-4862-8c42-01f8500619a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(object):\n",
    "    \"\"\"\n",
    "    A simple artificial neuron, processing an input vector and returning a corresponding activation.\n",
    "    Args:\n",
    "        num_inputs (int): The input vector size / number of input values.\n",
    "        activation_function (callable): The activation function defining this neuron.\n",
    "    Attributes:\n",
    "        W (ndarray): The weight values for each input.\n",
    "        b (float): The bias value, added to the weighted sum.\n",
    "        activation_function (callable): The activation function computing the neuron's output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs, activation_function):\n",
    "        super().__init__()\n",
    "\n",
    "        # Randomly initializing the weight vector and the bias value (e.g., using a simplistic \n",
    "        # uniform distribution between -1 and 1):\n",
    "        self.W = np.random.uniform(size=num_inputs, low=-1., high=1.)\n",
    "        self.b = np.random.uniform(size=1, low=-1., high=1.)\n",
    "\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward the input signal through the neuron, returning its activation value.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(1, num_inputs)`\n",
    "        Returns:\n",
    "            activation (ndarray): The activation value, of shape `(1, layer_size)`.\n",
    "        \"\"\"\n",
    "        z = np.dot(x, self.W) + self.b\n",
    "        return self.activation_function(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac36b4-7c81-4007-948e-dad5456b794e",
   "metadata": {},
   "source": [
    "- 뉴런을 인스턴스화한다. \n",
    "- 2개의 입력 값을 사용하여 활성화 계산을 위한 step function을 사용하여 퍼셉트론을 생성한다.\n",
    "- weights와 bias 값은 무작위로 설정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b25bd2a-beaa-422c-ac6a-ab1b485a365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron's random weights = [-0.25091976  0.90142861  0.46398788] , and random bias = [0.19731697]\n"
     ]
    }
   ],
   "source": [
    "# Perceptron input size:\n",
    "input_size = 3\n",
    "\n",
    "# Step function (returns 0 if y <= 0, or 1 if y > 0):\n",
    "step_function = lambda y: 0 if y <= 0 else 1\n",
    "\n",
    "# Instantiating the perceptron:\n",
    "perceptron = Neuron(num_inputs=input_size, activation_function=step_function)\n",
    "print(\"Perceptron's random weights = {} , and random bias = {}\".format(perceptron.W, perceptron.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24df80-9491-4dcf-b6d0-b58e1356d392",
   "metadata": {},
   "source": [
    "- 뉴런에 공급될 3개의 값(즉, (shape = (1, 3)의 column-vector)의 random input vector를 무작위로 생성한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63cdd217-950b-4c39-bdcc-d025b21747a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector : [[0.15601864 0.15599452 0.05808361]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(input_size).reshape(1, input_size)\n",
    "print(\"Input vector : {}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c29a2-1ccf-4315-9b54-4f41153e044f",
   "metadata": {},
   "source": [
    "- 이제 이 입력으로 퍼셉트론을 공급하고 그에 상응하는 활성화를 표시할 수 있다. \n",
    "- 다른 입력을 시도하거나 가중치를 바꿔보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e5cfb00-5d3e-4d36-b1c8-d1f92538819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron's output value given `x` : 1\n"
     ]
    }
   ],
   "source": [
    "y = perceptron.forward(x)\n",
    "print(\"Perceptron's output value given `x` : {}\".format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6c61b-b045-4889-9a74-d5237216ce0f",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d450396-bd82-4b16-a0c1-a52f6f7b0249",
   "metadata": {},
   "source": [
    "### 2. Layering Neurons Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a832a2c-a151-4c7e-99c0-4a9a6380d09f",
   "metadata": {},
   "source": [
    "- 1.에서는 뉴런이 어떻게 층으로 조직될 수 있는지 설명\n",
    "- 이러한 neural layer가 수행하는 작업을 수학적으로 함께 포장하는 다음 모델을 도입\n",
    "- Note: This class can also be found in **fully_connected_layer.py.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f54c783-4218-4b40-8ff5-0497491a7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(object):\n",
    "    \"\"\"A simple fully-connected NN layer.\n",
    "    Args:\n",
    "        num_inputs (int): The input vector size / number of input values.\n",
    "        layer_size (int): The output vector size / number of neurons in the layer.\n",
    "        activation_function (callable): The activation function for this layer.\n",
    "    Attributes:\n",
    "        W (ndarray): The weight values for each input.\n",
    "        b (ndarray): The bias value, added to the weighted sum.\n",
    "        size (int): The layer size / number of neurons.\n",
    "        activation_function (callable): The activation function computing the neuron's output.\n",
    "        x (ndarray): The last provided input vector, stored for backpropagation.\n",
    "        y (ndarray): The corresponding output, also stored for backpropagation.\n",
    "        derivated_activation_function (callable): The corresponding derivated function for backpropagation.\n",
    "        dL_dW (ndarray): The derivative of the loss, with respect to the weights W.\n",
    "        dL_db (ndarray): The derivative of the loss, with respect to the bias b.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs, layer_size, activation_function, derivated_activation_function=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Randomly initializing the weight vector and the bias value (using a normal distribution this time):\n",
    "        self.W = np.random.standard_normal((num_inputs, layer_size))\n",
    "        self.b = np.random.standard_normal(layer_size)\n",
    "        self.size = layer_size\n",
    "\n",
    "        self.activation_function = activation_function\n",
    "        self.derivated_activation_function = derivated_activation_function\n",
    "        self.x, self.y = None, None\n",
    "        self.dL_dW, self.dL_db = None, None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward the input vector through the layer, returning its activation vector.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(batch_size, num_inputs)`\n",
    "        Returns:\n",
    "            activation (ndarray): The activation value, of shape `(batch_size, layer_size)`.\n",
    "        \"\"\"\n",
    "        z = np.dot(x, self.W) + self.b\n",
    "        self.y = self.activation_function(z)\n",
    "        self.x = x  # (we store the input and output values for back-propagation)\n",
    "        return self.y\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        \"\"\"\n",
    "        Back-propagate the loss, computing all the derivatives, storing those w.r.t. the layer parameters,\n",
    "        and returning the loss w.r.t. its inputs for further propagation.\n",
    "        Args:\n",
    "            dL_dy (ndarray): The loss derivative w.r.t. the layer's output (dL/dy = l'_{k+1}).\n",
    "        Returns:\n",
    "            dL_dx (ndarray): The loss derivative w.r.t. the layer's input (dL/dx).\n",
    "        \"\"\"\n",
    "        dy_dz = self.derivated_activation_function(self.y)  # = f'\n",
    "        dL_dz = (dL_dy * dy_dz) # dL/dz = dL/dy * dy/dz = l'_{k+1} * f'\n",
    "        dz_dw = self.x.T\n",
    "        dz_dx = self.W.T\n",
    "        dz_db = np.ones(dL_dy.shape[0]) # dz/db = d(W.x + b)/db = 0 + db/db = \"ones\"-vector\n",
    "\n",
    "        # Computing the derivatives with respect to the layer's parameters, and storing them for opt. optimization:\n",
    "        self.dL_dW = np.dot(dz_dw, dL_dz)\n",
    "        self.dL_db = np.dot(dz_db, dL_dz)\n",
    "\n",
    "        # Computing the derivative with respect to the input, to be passed to the previous layers (their `dL_dy`):\n",
    "        dL_dx = np.dot(dL_dz, dz_dx)\n",
    "        return dL_dx\n",
    "\n",
    "    def optimize(self, epsilon):\n",
    "        \"\"\"\n",
    "        Optimize the layer's parameters, using the stored derivative values.\n",
    "        Args:\n",
    "            epsilon (float): The learning rate.\n",
    "        \"\"\"\n",
    "        self.W -= epsilon * self.dL_dW\n",
    "        self.b -= epsilon * self.dL_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1827ff86-9df9-418d-a5c4-8b3f5f694137",
   "metadata": {},
   "source": [
    "- 아래는, 이 계층이 입력 값을 하나씩 처리하거나 일괄적으로 쌓는 데 어떻게 사용될 수 있는지 확인하는 코드\n",
    "- 3개의 뉴런(그래서 3개의 출력 값)의 레이어를 인스턴스화하여 2개의 입력 값을 취하고 이번에는 활성화에 ReLU(Rectified Linear Unit) 기능을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77fc532-ce83-4a69-9322-16fe34e6b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size    = 2\n",
    "num_neurons   = 3\n",
    "relu_function = lambda y: np.maximum(y, 0)\n",
    "\n",
    "layer = FullyConnectedLayer(num_inputs=input_size, layer_size=num_neurons, activation_function=relu_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e0ef1-8944-492b-b37a-e7a411831c2e",
   "metadata": {},
   "source": [
    "- 랜덤한 input vector 2개를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0ee4e4-a965-455f-b4a5-8ffaed6194c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector #2: [[-0.72101228 -0.4157107 ]]\n",
      "Input vector #1: [[-0.26727631 -0.08786003]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.uniform(-1, 1, 2).reshape(1, 2)\n",
    "x2 = np.random.uniform(-1, 1, 2).reshape(1, 2)\n",
    "print(\"Input vector #2: {}\".format(x1))\n",
    "print(\"Input vector #1: {}\".format(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3d4cd-951e-47a4-bf2c-0bc04b9b2f5b",
   "metadata": {},
   "source": [
    "- 위의 레이어를 통해서 input들을 각각 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a991bec5-a006-4346-bdee-453b4acef788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer's output value given `x1` : [[0.         0.4593046  1.61941647]]\n",
      "Layer's output value given `x2` : [[0.         0.73048436 1.05288999]]\n"
     ]
    }
   ],
   "source": [
    "y1 = layer.forward(x1)\n",
    "y2 = layer.forward(x2)\n",
    "print(\"Layer's output value given `x1` : {}\".format(y1))\n",
    "print(\"Layer's output value given `x2` : {}\".format(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc24d55-a73c-44da-a408-503c4a0eb2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer's output value given `[x1, x2]` :\n",
      "[[0.         0.4593046  1.61941647]\n",
      " [0.         0.73048436 1.05288999]]\n"
     ]
    }
   ],
   "source": [
    "# stack of input vectors, of shape `(2, 2)`\n",
    "x12 = np.concatenate((x1, x2))  \n",
    "y12 = layer.forward(x12)\n",
    "print(\"Layer's output value given `[x1, x2]` :\\n{}\".format(y12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c8560-e3e9-4c5e-b6d9-fef2da88052f",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b46da-4684-4d85-9a22-d73530c31259",
   "metadata": {},
   "source": [
    "### 3. Implementing a Complete Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f732624-cd2c-4d28-9270-c9a58f43c855",
   "metadata": {},
   "source": [
    "\n",
    "- neural layers의 목적 : non-linear 예측을 수행할 수 있는 neural network(신경망)을 형성하기 위해 함께 stacked되는 것!\n",
    "- gradient descent(경사 하강법)을 적용하면, 그러한 네트워크는 정확한 예측을 수행하도록 훈련될 수 있다(1장의 c.f. 이론). \n",
    "    - 그러나 이를 위해서는 네트워크의 성능을 평가하기 위한 **손실 함수**(c.f. L2 또는 cross-entropy)가 필요\n",
    "    - 네트워크에서 수행되는 모든 작업을 도출하고,  **그레이디언트를 계산**하고,  **전파**하는 방법을 알아야 한다.\n",
    "- 아래에서부터는 간단한 fully-connected neural network가 구축될 수 있는 방법을 제시\n",
    "    - 네트워크가 activation을 위해 sigmoid function을 사용하기를 원한다고 가정\n",
    "    - function과 그것의 derivative를 구현할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e8f62-2921-4433-ab87-808bfcd1cca7",
   "metadata": {},
   "source": [
    "#### 1) activation function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "794ddd74-317f-4a49-ba2e-3ba3568e2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):             # sigmoid function\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y\n",
    "\n",
    "\n",
    "def derivated_sigmoid(y):   # sigmoid derivative function\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfe7a8-ce62-4c33-b5a2-02ab2919fdb2",
   "metadata": {},
   "source": [
    "#### 2) loss 정의 \n",
    "- classification을 위한 neural network를 만든다고 가정한다.\n",
    "    - L2 또는 cross-entropy 사용\n",
    "    - 위의 내용을 구현하고, 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d513d8b0-94ec-4040-91a0-6bf7be9450d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_L2(pred, target):             # L2 loss function\n",
    "    return np.sum(np.square(pred - target)) / pred.shape[0] # opt. we divide by the batch size\n",
    "\n",
    "\n",
    "def derivated_loss_L2(pred, target):   # L2 derivative function\n",
    "    return 2 * (pred - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff41ed44-fa85-464f-bd86-63af74ff4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(pred, target):            # cross-entropy loss function\n",
    "    return -np.mean(np.multiply(np.log(pred), target) + np.multiply(np.log(1 - pred), (1 - target)))\n",
    "\n",
    "\n",
    "def derivated_binary_cross_entropy(pred, target):  # cross-entropy derivative function\n",
    "    return (pred - target) / (pred * (1 - pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f4e3b-1ac8-4179-98ae-6bd19756e388",
   "metadata": {},
   "source": [
    "#### 3) 클래스 구축\n",
    "- **위의 내용까지는 여기서 사용할 함수들을 정의**, **이제부터는 진짜 구현해보기 위한 모델 구축 단계**\n",
    "- 이제 모든 것을 함께 연결하여 -> 여러 신경 계층을 연결할 수 있는 클래스를 구축\n",
    "- 이러한 계층을 통해 데이터를 feed-forward\n",
    "- 훈련을 위해 loss'gradients를 back-propagate할 수 있어야 한다.\n",
    "- Note: This class can also be found in **simple_network.py.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0359cbf8-069b-472b-8c7c-75b386995705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(object):\n",
    "    \"\"\"A simple fully-connected NN.\n",
    "    Args:\n",
    "        num_inputs (int): The input vector size / number of input values.\n",
    "        num_outputs (int): The output vector size.\n",
    "        hidden_layers_sizes (list): A list of sizes for each hidden layer to add to the network\n",
    "        activation_function (callable): The activation function for all the layers\n",
    "        derivated_activation_function (callable): The derivated activation function\n",
    "        loss_function (callable): The loss function to train this network\n",
    "        derivated_loss_function (callable): The derivative of the loss function, for back-propagation\n",
    "    Attributes:\n",
    "        layers (list): The list of layers forming this simple network.\n",
    "        loss_function (callable): The loss function to train this network.\n",
    "        derivated_loss_function (callable): The derivative of the loss function, for back-propagation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_layers_sizes=(64, 32),\n",
    "                 activation_function=sigmoid, derivated_activation_function=derivated_sigmoid,\n",
    "                 loss_function=loss_L2, derivated_loss_function=derivated_loss_L2):\n",
    "        super().__init__()\n",
    "        # We build the list of layers composing the network, according to the provided arguments:\n",
    "        layer_sizes = [num_inputs, *hidden_layers_sizes, num_outputs]\n",
    "        self.layers = [\n",
    "            FullyConnectedLayer(layer_sizes[i], layer_sizes[i + 1], \n",
    "                                activation_function, derivated_activation_function)\n",
    "            for i in range(len(layer_sizes) - 1)]\n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.derivated_loss_function = derivated_loss_function\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward the input vector through the layers, returning the output vector.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(batch_size, num_inputs)`.\n",
    "        Returns:\n",
    "            activation (ndarray): The output activation value, of shape `(batch_size, layer_size)`.\n",
    "        \"\"\"\n",
    "        for layer in self.layers: # from the input layer to the output one\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Compute the output corresponding to input `x`, and return the index of the largest \n",
    "        output value.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(1, num_inputs)`.\n",
    "        Returns:\n",
    "            best_class (int): The predicted class ID.\n",
    "        \"\"\"\n",
    "        estimations = self.forward(x)\n",
    "        best_class = np.argmax(estimations)\n",
    "        return best_class\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        \"\"\"\n",
    "        Back-propagate the loss hrough the layers (require `forward()` to be called before).\n",
    "        Args:\n",
    "            dL_dy (ndarray): The loss derivative w.r.t. the network's output (dL/dy).\n",
    "        Returns:\n",
    "            dL_dx (ndarray): The loss derivative w.r.t. the network's input (dL/dx).\n",
    "        \"\"\"\n",
    "        for layer in reversed(self.layers): # from the output layer to the input one\n",
    "            dL_dy = layer.backward(dL_dy)\n",
    "        return dL_dy\n",
    "\n",
    "    def optimize(self, epsilon):\n",
    "        \"\"\"\n",
    "        Optimize the network parameters according to the stored gradients (require `backward()`\n",
    "        to be called before).\n",
    "        Args:\n",
    "            epsilon (float): The learning rate.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:             # the order doesn't matter here\n",
    "            layer.optimize(epsilon)\n",
    "\n",
    "    def evaluate_accuracy(self, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Given a dataset and its ground-truth labels, evaluate the current accuracy of the network.\n",
    "        Args:\n",
    "            X_val (ndarray): The input validation dataset.\n",
    "            y_val (ndarray): The corresponding ground-truth validation dataset.\n",
    "        Returns:\n",
    "            accuracy (float): The accuracy of the network \n",
    "                              (= number of correct predictions/dataset size).\n",
    "        \"\"\"\n",
    "        num_corrects = 0\n",
    "        for i in range(len(X_val)):\n",
    "            pred_class = self.predict(X_val[i])\n",
    "            if pred_class == y_val[i]:\n",
    "                num_corrects += 1\n",
    "        return num_corrects / len(X_val)\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, \n",
    "              batch_size=32, num_epochs=5, learning_rate=1e-3, print_frequency=20):\n",
    "        \"\"\"\n",
    "        Given a dataset and its ground-truth labels, evaluate the current accuracy of the network.\n",
    "        Args:\n",
    "            X_train (ndarray): The input training dataset.\n",
    "            y_train (ndarray): The corresponding ground-truth training dataset.\n",
    "            X_val (ndarray): The input validation dataset.\n",
    "            y_val (ndarray): The corresponding ground-truth validation dataset.\n",
    "            batch_size (int): The mini-batch size.\n",
    "            num_epochs (int): The number of training epochs i.e. iterations over the whole dataset.\n",
    "            learning_rate (float): The learning rate to scale the derivatives.\n",
    "            print_frequency (int): Frequency to print metrics (in epochs).\n",
    "        Returns:\n",
    "            losses (list): The list of training losses for each epoch.\n",
    "            accuracies (list): The list of validation accuracy values for each epoch.\n",
    "        \"\"\"\n",
    "        num_batches_per_epoch = len(X_train) // batch_size\n",
    "        do_validation = X_val is not None and y_val is not None\n",
    "        losses, accuracies = [], []\n",
    "        for i in range(num_epochs): # for each training epoch\n",
    "            epoch_loss = 0\n",
    "            for b in range(num_batches_per_epoch):  # for each batch composing the dataset\n",
    "                # Get batch:\n",
    "                batch_index_begin = b * batch_size\n",
    "                batch_index_end = batch_index_begin + batch_size\n",
    "                x = X_train[batch_index_begin: batch_index_end]\n",
    "                targets = y_train[batch_index_begin: batch_index_end]\n",
    "                # Optimize on batch:\n",
    "                predictions = y = self.forward(x)  # forward pass\n",
    "                L = self.loss_function(predictions, targets)  # loss computation\n",
    "                dL_dy = self.derivated_loss_function(predictions, targets)  # loss derivation\n",
    "                self.backward(dL_dy)  # back-propagation pass\n",
    "                self.optimize(learning_rate)  # optimization of the NN\n",
    "                epoch_loss += L\n",
    "\n",
    "            # Logging training loss and validation accuracy, to follow the training:\n",
    "            epoch_loss /= num_batches_per_epoch\n",
    "            losses.append(epoch_loss)\n",
    "            if do_validation:\n",
    "                accuracy = self.evaluate_accuracy(X_val, y_val)\n",
    "                accuracies.append(accuracy)\n",
    "            else:\n",
    "                accuracy = np.NaN\n",
    "            if i % print_frequency == 0 or i == (num_epochs - 1):\n",
    "                print(\"Epoch {:4d}: training loss = {:.6f} | val accuracy = {:.2f}%\".format(\n",
    "                    i, epoch_loss, accuracy * 100))\n",
    "        return losses, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36c426-2027-4557-950a-0882e0be95ea",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a798771-aa9e-44e5-8d6c-cff140f84668",
   "metadata": {},
   "source": [
    "### 4. Applying our Network to Classification\n",
    "- 손으로 쓴 숫자의 이미지를 분류하기 위해 간단한 모델을 인스턴스화하고 훈련한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237f776-1c1a-4e80-a34b-77a357ace2c2",
   "metadata": {},
   "source": [
    "#### 1) Setting up the Task\n",
    "- mnist module은 training and testing data를 로드하는데 있어서 간단하다.\n",
    "- 단, minst 폴더와 __init__.py 파일이 없으면 로드 안되므로 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8563a5b-276c-4844-b775-ae251cc09c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# !pip install matplotlib  # Uncomment and run if matplotlib is not installed yet.\n",
    "import matplotlib          # We use this package to visualize some data and results\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba24b57-0a7a-4d49-9842-39e506ce3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist.train_images(), mnist.train_labels()\n",
    "X_test,  y_test  = mnist.test_images(), mnist.test_labels()\n",
    "num_classes = 10    # classes are the digits from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740d381-a0a3-4888-814e-c5047b9db680",
   "metadata": {},
   "source": [
    "- training/testing samples의 number, size 확인\n",
    "    - 28x28 픽셀을 가진 60,000 training samples and 10,000 testing 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bf86e7b-b935-4c5e-9114-3cd51141fd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5900cbb-0e2b-4fbe-9b41-07a8b92515a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c56d76-a63f-48a2-9bd1-ac0a03b0d25d",
   "metadata": {},
   "source": [
    "- matplotlib을 사용해서 데이터 확인 가능\n",
    "    - 이미지와 ground-truth label이 잘 매치한 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08cbbdeb-c5d1-4eaf-997b-7a5cc6b33cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_idx = np.random.randint(0, X_test.shape[0])\n",
    "plt.imshow(X_test[img_idx], cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f4286c0-3d24-438c-ab9f-8142bdc1b0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[img_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ec479-57ba-4ecf-8864-0320961e33ad",
   "metadata": {},
   "source": [
    "- 그러나 우리의 네트워크는 **열 벡터**만 받아들이기 때문에\n",
    "- 이미지 -> 1D 벡터로 변환해서 flatten해야 한다.\n",
    "    - 즉, **shape(1, 784)의 벡터**\n",
    "    - 28x28 = 784이므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900f8a4b-1cf6-4641-b12b-43c53e8a06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중요중요\n",
    "X_train, X_test = X_train.reshape(-1, 28 * 28), X_test.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75634816-ba9f-4be4-9dff-9a026b17b6aa",
   "metadata": {},
   "source": [
    "- 픽셀 값 살펴보기\n",
    "    - 이 값은 채널당 8비트(unit8)인 영상에 대한 일반 정수 값이다.\n",
    "    - 그러나 일부 작업에 비해 너무 클 수 있다.\n",
    "        - 예를 들어, 너무 큰 값이 주어지면 시그모이드느느 사용하는 지수 함수 때문에 nan(\"not a number\")을 반환할 수 있으며, 이는 큰 입력값으로 \"overflow\"할 수 있다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f853c66f-35f5-4f83-8801-fa79a41b2a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values between 0 and 255\n"
     ]
    }
   ],
   "source": [
    "print(\"Pixel values between {} and {}\".format(X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d592543-fced-4e49-91c1-c084f702f257",
   "metadata": {},
   "source": [
    "- 따라서 입력 데이터를 정규화하는 것이 일반적\n",
    "    - 즉, 값을 0과 1(또는 -1과 1) 사이로 조정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "952da9a8-1455-4f3e-b93f-e33fe6b3cc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized pixel values between 0.0 and 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train/255., X_test/255.\n",
    "print(\"Normalized pixel values between {} and {}\".format(X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f0b14-3f0a-4506-a8ce-9daedd862214",
   "metadata": {},
   "source": [
    "- loss를 계산하기 위해, labels을 one-hot 인코딩\n",
    "    - 예를 들어, label 4를 [0, 0, 0, 1, 0, 0, 0, 0, 0]로 변환ㅡ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36bafd13-7ee1-48b8-b442-b3a9f326f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(num_classes)[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c302e14-8bb4-40cd-82f3-6ca330f9d596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d48a2b-b94a-4693-9117-48921b2b2420",
   "metadata": {},
   "source": [
    "#### 2) Instantiating the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def1776-68d3-429f-9301-fa937cda5063",
   "metadata": {},
   "source": [
    "- SimpleNetwork 클래스를 사용\n",
    "- 2개의 hidden layer로 네트워크를 인스턴스화\n",
    "- flattened image를 입력으로 가져오기\n",
    "- 이미지가 클래스 각각에 속한다는 belief를 나타내는 10-value 벡터를 반환(값이 높을수록 더 강한 belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1579ceb0-1239-455b-9e14-70a88b58786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier = SimpleNetwork(num_inputs=X_train.shape[1], \n",
    "                                 num_outputs=num_classes, hidden_layers_sizes=[64, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa133110-7b78-49b7-8a2e-a21fe15fd00d",
   "metadata": {},
   "source": [
    "- 우리의 네트워크 성능을 체크할 수 있다.\n",
    "    - 이것의 training set에 대한 loss, test set에 대한 accuracy\n",
    "    - 성능이 매우 낮지만 아직 훈련 전!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7639dfb9-acf8-413b-bc5e-d7dc00038fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained : training loss = 4.436700 | val accuracy = 12.19%\n"
     ]
    }
   ],
   "source": [
    "predictions = mnist_classifier.forward(X_train)                         # forward pass\n",
    "loss_untrained = mnist_classifier.loss_function(predictions, y_train)   # loss computation\n",
    "\n",
    "accuracy_untrained = mnist_classifier.evaluate_accuracy(X_test, y_test)  # Accuracy\n",
    "print(\"Untrained : training loss = {:.6f} | val accuracy = {:.2f}%\".format(\n",
    "    loss_untrained, accuracy_untrained * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbca79-8c60-4bb7-811c-1e92c61f85e8",
   "metadata": {},
   "source": [
    "#### 3) Teaching our Network to Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af09ada8-236d-4e08-b521-09308e20205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: training loss = 1.096978 | val accuracy = 19.10%\n",
      "Epoch   20: training loss = 0.252953 | val accuracy = 84.89%\n",
      "Epoch   40: training loss = 0.177532 | val accuracy = 88.92%\n",
      "Epoch   49: training loss = 0.161194 | val accuracy = 89.64%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = mnist_classifier.train(X_train, y_train, X_test, y_test, \n",
    "                                            batch_size=30, num_epochs=50)\n",
    "# note: Reduce the batch size and/or number of epochs if your computer can't \n",
    "#       handle the computations / takes too long.\n",
    "#       Remember, numpy also uses the CPU, not GPUs as modern Deep Learning \n",
    "#       libraries do, hence the lack of computational performance here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d46f06-3114-4585-bc98-5bd4cb5b02f3",
   "metadata": {},
   "source": [
    "- 시각화를 위해 training 동안 loss, accuracy의 evolution을 plot할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbdd2073-90ad-4afe-9d41-93d397b3e633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses, accuracies = [loss_untrained] + losses, [accuracy_untrained] + accuracies\n",
    "fig, ax_loss = plt.subplots()\n",
    "\n",
    "color = 'red'\n",
    "ax_loss.set_xlim([0, 510])\n",
    "ax_loss.set_xlabel('Epochs')\n",
    "ax_loss.set_ylabel('Training Loss', color=color)\n",
    "ax_loss.plot(losses, color=color)\n",
    "ax_loss.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax_acc = ax_loss.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'blue'\n",
    "ax_acc.set_xlim([0, 510])\n",
    "ax_acc.set_ylim([0, 1])\n",
    "ax_acc.set_ylabel('Val Accuracy', color=color)\n",
    "ax_acc.plot(accuracies, color=color)\n",
    "ax_acc.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e246dfe-b462-488b-8294-74a7efd9251c",
   "metadata": {},
   "source": [
    "- 랜덤 테스트 이미지에서 네트워크가 현재 어떻게 작동하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f13270d3-f881-4d58-911f-f520f35c4f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1; Correct class: 1\n"
     ]
    }
   ],
   "source": [
    "# We use `np.expand_dims(x, 0)` to simulate a batch (transforming the image shape\n",
    "# from (784,) to (1, 784)):\n",
    "predicted_class = mnist_classifier.predict(np.expand_dims(X_test[img_idx], 0))\n",
    "print('Predicted class: {}; Correct class: {}'.format(predicted_class, y_test[img_idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nozzi",
   "language": "python",
   "name": "nozzi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
